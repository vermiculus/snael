#+Title: SNAEL: A Social Network Analyzer for English Literature
#+Author: Sean Allred
#+Date: [2013-04-20 Sat]

#+BEGIN_SRC python :tangle "./src/snael.py"
  print "Welcome to SNAEL, version 0.2"
#+END_SRC

* What are we Studying?
We are studying the social networks within a text stored in the
following file, served from [[http://fileserver.booktrust.org.uk/usr/library/documents/bbc-nssa-2009/other_peoples_gods.pdf][BookTrust.org]] on [2013-04-08 Mon].  The
file has been edited from its original form, but the text has not been
altered.

The work is entitled /Other People's Gods/ and was written by Naomi
Alderman, winning the 2009 BBC National Short Story Award, and is
freely available on-line.

#+BEGIN_SRC python :tangle "./src/snael.py"
  FILE_NAME = '../text/simple.txt'
#+END_SRC

* Wait, what is a Network?
A network is a graph---it is a collection of entities (usually called
'nodes') that are connected to each other in certain ways.

For the purposes of this research, the following =Network= class
defines a consistent interface for accumulating a weighted graph.

A =Network= has exactly one field, a dictionary of associations.  The
dictionary uses entities (must be hash-able, e.g. strings) as keys and
one more dictionary as values.  This inner dictionary maps entities
onto weights.  Care has been taken to ensure that new entities are
appropriately handled and connections are two-way (adding a connection
from $A \to B$ is the same as adding a connection from $B \to A$).
#+BEGIN_SRC python :tangle "./src/snael.py"
  class Network:
      def __init__(self):
          self.associations = dict()
      def addConnection(self, entityA, entityB):
          if entityA not in self.associations:
              self.associations[entityA]=dict()
          if entityB not in self.associations:
              self.associations[entityB]=dict()
  
          if entityA not in self.associations[entityB]:
              self.associations[entityB][entityA] = 0
          if entityB not in self.associations[entityA]:
              self.associations[entityA][entityB] = 0
  
          self.associations[entityA][entityB] += 1
          self.associations[entityB][entityA] += 1
#+END_SRC

* Load Text
Obviously, the first thing of significance we do is load the file into
memory.  This snippet of code opens =FILE_NAME= as read-only and loads
the full contents into =raw=.
#+BEGIN_SRC python :tangle "./src/snael.py"
  with open(FILE_NAME, 'r') as f:
      print '>reading file'
      raw = ''.join(f.readlines())
      print '>file read'
#+END_SRC

* Tokenize Text
#+BEGIN_SRC python :tangle "./src/snael.py"
  print '>importing nltk'
  import nltk
  print '>tokenizing'
  tokens = nltk.sent_tokenize(raw)
  tokens = [t.replace('\n',' ').replace('  ',' ') \
            for t in tokens if t is not '.']
  
  print '>converting to nltk.Text'
  text = nltk.Text(tokens)
#+END_SRC

* Create List of Names
** Tagging the Text
We need to make sure that we have a list of all names.  Let's just
create a pipeline to tokenize, tag, and chunk a text, using a
simplified regular expression to detect names.

#+BEGIN_SRC python :tangle "./src/snael.py"
  grammer = r'NAME: {<NNP>+(<DT>?<NNP>+)?}'
  ne_chunker = nltk.RegexpParser(grammer)
  entities = lambda text: \
             ne_chunker.parse( \
              nltk.pos_tag( \
               nltk.word_tokenize(text)))
#+END_SRC

Switching on the =binary= option tells NLTK to enable only one type of
named entity, instead of trying to recognize organizations, places,
names, and other specifics.  With this option, NLTK seems to be far
more reliable and consistent.

** Recognizing Names
Now, =entities= is a function that, if we pass it some sentence, it
can correctly identify many titles as named entities:

#+BEGIN_EXAMPLE
>>> print entities("Alexander conquered much of the known world \
    after his father, Phillip II, was assassinated.").pprint()
(S
  (NE Alexander/NNP)
  conquered/VBD
  much/JJ
  of/IN
  the/DT
  known/VBN
  world/NN
  after/IN
  his/PRP$
  father/NN
  ,/,
  (NE Phillip/NNP II/NNP)
  ,/,
  was/VBD
  assassinated/VBN
  ./.)
#+END_EXAMPLE

Note, however, that NLTK is not foolproof; it is yet confused by the
following simple epithet:

#+BEGIN_EXAMPLE
>>> print entities("Alexander the Great conquered much of the known \
    world after his father, Phillip II, was assassinated.").pprint()
(S
  Alexander/NNP
  the/DT
  (NE Great/NNP)
  conquered/VBD
  much/JJ
  of/IN
  the/DT
  known/VBN
  world/NN
  after/IN
  his/PRP$
  father/NN
  ,/,
  (NE Phillip/NNP II/NNP)
  ,/,
  was/VBD
  assassinated/VBN
  ./.)
#+END_EXAMPLE

This can most certainly present problems when the names are followed
by an epithet that is crucial to correctly identifying the person, as
in =Alexander the Great=.  (This is called an /epitheton
necessarium/.)  I suspect an NLTK chunking object can be configured to
correctly identify these by placing an optional determiner between two
proper nouns (tagged =NNP=), but we will ignore this shortcoming for
now.

We now need to tag every sentence in the text.  This is by far the
most time-consuming task, and the program can appear that it is
frozen.  For this reason, an incremental update system is put into
place to advise the user on its progress.  The progress bar system is
taken from [[http://stackoverflow.com/a/3160819/1443496][Stack Overflow]] and is available under the
Creative~Commons~BY-SA.  The original code was written by
[[http://stackoverflow.com/users/81179][CristopheD]] and has been modified to be clearer.

#+BEGIN_SRC python :tangle "./src/snael.py"
  progress_bar_width = 70
  progress_bar_progress = 0

  import sys

  # Write out the bar
  sys.stdout.write("[%s]" % (" " * progress_bar_width))
  
  # Flush the output stream (force write)
  sys.stdout.flush()
  
  # Return to the start of the bar
  sys.stdout.write("\b" * (progress_bar_width+1))
#+END_SRC

We prepare a list for the tagged sentences to be stored, and begin to
track our progress through the text.  (Remember that the text is
stored as a list of sentences, so this progress is
sentence-by-sentence.)  For each =sentence= in the =text=, we append
the list of =tagged_senteces= with the =entities= of the =sentence=.
We increment our progress through the text, and then test to see if we
have crossed into the next level of the progress bar.  (We do this by
comparing the ratios between =current_text_index= : =len(text)= and
=progress_bar=progress= : =progress_bar_width=.  Each value is
interpreted as a =float= to bypass integer division.)  If we need to,
we write a character to =stdout=, flush the buffer (forcing the
write), and then increment our progress through the progress bar.

#+BEGIN_SRC python :tangle "./src/snael.py"
  tagged_sentences = list()
  
  current_text_index = 0

  print '>tagging entire text'
  for sentence in text:
      tagged_sentences.append(entities(sentence))
      current_text_index += 1
      if float(current_text_index) / float(len(text)) > \
         float(progress_bar_progress) / float(progress_bar_width):
          sys.stdout.write('-')
          sys.stdout.flush()
          progress_bar_progress += 1
  print ''
  print '>Done.'
#+END_SRC

*** Resolve Anaphora
We now have =tagged_sentences= in memory; we have a /complete/ tagged
list of all words in the text, and have (hopefully) recognized all
explicit names.

But what about /implicit/ names?  In English, it is common to have
/anaphora/, the 'fancy term' for these implicit names.

Nota Bene: there are two differing definitions of /anaphora/:

1. the rhetorical device of repeating a sentence structure for
   emphasis
2. an expression who reference depends upon another referential
   expression

For example, the following phrase exhibits two cases of anaphora:

#+BEGIN_EXAMPLE
The fat cat tripped on itself.  The mouse then laughed at it.
#+END_EXAMPLE

**** The Problem
It is important to note that anaphora can manifest itself in reflexive
pronouns (/itself/) and in nominal pronouns (/it/), and neither need
be in the same sentence.  Furthermore, in objective pronouns, the
antecedant is often found further back in the text:

#+BEGIN_EXAMPLE
And he said, 'Then why do you worship Him?'
#+END_EXAMPLE
(cite)

In this example, =he= is referring to =Mr Bloom= (the protagonist) and
=Him= is referring to God, an entity named in dialogue.  Moreover,
consider the (contrived) example,

#+BEGIN_EXAMPLE
Pleased with himself, Matthew showed her the painting he drew.
#+END_EXAMPLE

And, for goodness' sake,

#+BEGIN_EXAMPLE
It is raining outside.
#+END_EXAMPLE

So we know a couple of things:

1. The pronoun can come before the noun.
2. The pronoun is almost /always/ gender-sensitive.
3. Due to the above, the pronoun can 'skip' other nouns and pronouns
   in order to reach its intended reference.
4. Sometimes, there simply /is no antecedant/.

Thus we are presented with many problems:

1. Resolving a pronoun isn't as easy as scanning the text and
   replacing each with the noun that precedes it.  (Even =it= skips
   =noun= and =text= to reach =pronoun=.)
2. The gender of pronouns raise worse issues still; it is almost
   impossible to determine the gender of a name without a dictionary
   and, if a pseudonym is gender-agnostic, it is simply impossible to
   resolve without multiple passes of a more advanced algorithm that
   can detect aliases.
3. Should such non-gendered actors exist, how can they be
   distinguished from non-actors?  (=The Spirit watched the city it
   guarded.=, where more complicated examples surely exist.)

The list goes on.  There is an existing portion of NLTK
(=nltk.sem.drt=) that 'deals with' anaphora, but its implementation is
needlessly cryptic for our purposes, difficult to work with, and
completely unreliable.  We will approach this with a basic, imperfect
algorithm that will resolve /some/ of the references, but will surely
not resolve /all/ of them.  It is better to miss a reference than to
create a wrong one, which NLTK's will often do.

**** The 'Solution'
Since we know this algorithm will be imperfect, we will encapsulate it
in its own method, =resolve_anaphora(text)=, which will simply return
a copy of =text= after replacing every positive instance of resolvable
anaphora with its antecedant.

TODO: sift out =NE= items in the =Tree= and then construct the list of
names.  May need to alter use of =Network= to allow for aliases.

#+BEGIN_SRC python :tangle "./src/snael.py"
  names = ['Fabantou', 'Leblanc', 'Jondrette']
  #  text  = list() #of sentences, lines, or whatever

  def list2dict(l,dv=set()):
      d=dict()
      for e in l:
          d[e]=dv
      return d
#+END_SRC

* Find Occurances
First we need to prepare a data structure for the occurances to live
in.  The obvious choice is a dictionary, with names as keys and lists
of locations as values.  So, to create this dictionary:

#+BEGIN_SRC python :tangle "./src/snael.py"
  occurances = dict()
  for name in names:
      occurances[name] = list()
#+END_SRC

Now find occurances and store them.

#+BEGIN_SRC python :tangle "./src/snael.py"
  for name in occurances.keys():
      for sentence in text:
          if name in sentence:
              names[name].append(text.index(sentence))
#+END_SRC

* Resolve Aliases
Somehow resolve aliases and combine lists of occurances accordingly

* Output
