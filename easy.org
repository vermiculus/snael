#+Title: SNAEL: A Social Network Analyzer for English Literature
#+Author: Sean Allred
#+Date: [2013-04-20 Sat]

#+BEGIN_SRC python :tangle "./src/snael.py"
  print "Welcome to SNAEL, version 0.3"
#+END_SRC

* TODO What are we Studying?
We are studying the social networks within a text stored in the
following file, served from [[http://fileserver.booktrust.org.uk/usr/library/documents/bbc-nssa-2009/other_peoples_gods.pdf][BookTrust.org]] on [2013-04-08 Mon].  The
file has been edited from its original form, but the text has not been
altered.

The work is entitled /Other People's Gods/ and was written by Naomi
Alderman, winning the 2009 BBC National Short Story Award, and is
freely available on-line.

#+BEGIN_SRC python :tangle "./src/snael.py"
  FILE_NAME = '../text/simple.txt'
#+END_SRC

* TODO Wait, what is a Network?
A network is a graph---it is a collection of entities (usually called
'nodes') that are connected to each other in certain ways.

For the purposes of this research, the following =Network= class
defines a consistent interface for accumulating a weighted graph.

A =Network= has exactly one field, a dictionary of associations.  The
dictionary uses entities (must be hash-able, e.g. strings) as keys and
one more dictionary as values.  This inner dictionary maps entities
onto weights.  Care has been taken to ensure that new entities are
appropriately handled and connections are two-way (adding a connection
from $A \to B$ is the same as adding a connection from $B \to A$).
#+BEGIN_SRC python :tangle "./src/snael.py"
  class Network:
      def __init__(self):
          self.associations = dict()
      def addConnection(self, entityA, entityB):
          if entityA not in self.associations:
              self.associations[entityA]=dict()
          if entityB not in self.associations:
              self.associations[entityB]=dict()
  
          if entityA not in self.associations[entityB]:
              self.associations[entityB][entityA] = 0
          if entityB not in self.associations[entityA]:
              self.associations[entityA][entityB] = 0
  
          self.associations[entityA][entityB] += 1
          self.associations[entityB][entityA] += 1
#+END_SRC

* DONE Load Text
Obviously, the first thing of significance we do is load the file into
memory.  This snippet of code opens =FILE_NAME= as read-only and loads
the full contents into =raw=.
#+BEGIN_SRC python :tangle "./src/snael.py"
  with open(FILE_NAME, 'r') as f:
      print '>reading file'
      raw = ''.join(f.readlines())
      print '>file read'
#+END_SRC

* DONE Tokenize Text
#+BEGIN_SRC python :tangle "./src/snael.py"
  print '>importing nltk'
  import nltk
  print '>tokenizing'
  tokens = nltk.sent_tokenize(raw)
  tokens = [t.replace('\n',' ').replace('  ',' ') \
            for t in tokens if t is not '.']
  
  print '>converting to nltk.Text'
  text = nltk.Text(tokens)
#+END_SRC

* TODO Create List of Names
** DONE Prepare a Grammar
We need to make sure that we have a list of all names.  Let's just
create a pipeline to tokenize, tag, and chunk a text, using a
simplified regular expression to detect names.

#+BEGIN_SRC python :tangle "./src/snael.py"
  grammer = r'NAME: {<NNP>+(<DT>?<NNP>+)?}'
  ne_chunker = nltk.RegexpParser(grammer)
  entities = lambda text: \
             ne_chunker.parse( \
              nltk.pos_tag( \
               nltk.word_tokenize(text)))
#+END_SRC

Switching on the =binary= option tells NLTK to enable only one type of
named entity, instead of trying to recognize organizations, places,
names, and other specifics.  With this option, NLTK seems to be far
more reliable and consistent.

** TODO Recognizing Names
*** DONE Shortcomings
Now, =entities= is a function that, if we pass it some sentence, it
can correctly identify many titles as named entities:

#+BEGIN_EXAMPLE
>>> print entities("Alexander conquered much of the known world \
    after his father, Phillip II, was assassinated.").pprint()
(S
  (NE Alexander/NNP)
  conquered/VBD
  much/JJ
  of/IN
  the/DT
  known/VBN
  world/NN
  after/IN
  his/PRP$
  father/NN
  ,/,
  (NE Phillip/NNP II/NNP)
  ,/,
  was/VBD
  assassinated/VBN
  ./.)
#+END_EXAMPLE

Note, however, that NLTK is not foolproof; it is yet confused by the
following simple epithet:

#+BEGIN_EXAMPLE
>>> print entities("Alexander the Great conquered much of the known \
    world after his father, Phillip II, was assassinated.").pprint()
(S
  Alexander/NNP
  the/DT
  (NE Great/NNP)
  conquered/VBD
  much/JJ
  of/IN
  the/DT
  known/VBN
  world/NN
  after/IN
  his/PRP$
  father/NN
  ,/,
  (NE Phillip/NNP II/NNP)
  ,/,
  was/VBD
  assassinated/VBN
  ./.)
#+END_EXAMPLE

This can most certainly present problems when the names are followed
by an epithet that is crucial to correctly identifying the person, as
in =Alexander the Great=.  (This is called an /epitheton
necessarium/.)  I suspect an NLTK chunking object can be configured to
correctly identify these by placing an optional determiner between two
proper nouns (tagged =NNP=), but we will ignore this shortcoming for
now.

*** DONE Tagging
We now need to tag every sentence in the text.  This is by far the
most time-consuming task, and the program can appear that it is
frozen.  For this reason, an incremental update system is put into
place to advise the user on its progress.  The progress bar system is
taken from [[http://stackoverflow.com/a/3160819/1443496][Stack Overflow]] and is available under
Creative~Commons~BY-SA.  The original code was written by [[http://stackoverflow.com/users/81179][CristopheD]]
and has been modified to be clearer.

#+BEGIN_SRC python :tangle "./src/snael.py"
  print '>tagging entire text'
  progress_bar_width = 70
  progress_bar_progress = 0

  import sys

  # Write out the bar
  sys.stdout.write("[%s]" % (" " * progress_bar_width))
  
  # Flush the output stream (force write)
  sys.stdout.flush()
  
  # Return to the start of the bar
  sys.stdout.write("\b" * (progress_bar_width+1))
#+END_SRC

We prepare a list for the tagged sentences to be stored, and begin to
track our progress through the text.  (Remember that the text is
stored as a list of sentences, so this progress is
sentence-by-sentence.)  For each =sentence= in the =text=, we append
the list of =tagged_senteces= with the =entities= of the =sentence=.
We increment our progress through the text, and then test to see if we
have crossed into the next level of the progress bar.  (We do this by
comparing the ratios between =current_text_index= : =len(text)= and
=progress_bar=progress= : =progress_bar_width=.  Each value is
interpreted as a =float= to bypass integer division.)  If we need to,
we write a character to =stdout=, flush the buffer (forcing the
write), and then increment our progress through the progress bar.

#+BEGIN_SRC python :tangle "./src/snael.py"
  tagged_sentences = list()
  
  current_text_index = 0

  for sentence in text:
      tagged_sentences.append(entities(sentence))
      current_text_index += 1
      if float(current_text_index) / float(len(text)) > \
         float(progress_bar_progress) / float(progress_bar_width):
          sys.stdout.write('-')
          sys.stdout.flush()
          progress_bar_progress += 1
  print ''
  print '>Done.'
#+END_SRC
*** TODO Strip Names
=tagged_sentences= is now a list that contains every sentence with
every word tagged as to its position.  Names are all tagged as such
(=NAME=), so all we need to do is distill the entire text into a list
of names.

In good practice, we'll define a function that will receive exactly
one sentence (as tagged by NLTK) and pull out the names, returning
them as a list.

We can use the production rules to extract the names.  For each
=NAME= recognized, a production is made from =NAME= to the actual
name matched.  The actual name matched is stored in the right-hand
side, or =rhs=, of the production list (given by
=sentence.productions()=).  (Note that the first production is always
from =S= (the sentence) to the sentence itself, with =NAME= standing
in for matched names.)  The =rhs= is stored in a tuple of tuples, and
a bit of indexing magic is done to extract what is needed (the first
element of each tuple).  This is then joined with a single space and
added to the list of names, which is returned.
#+BEGIN_SRC python :tangle "./src/snael.py"
  def get_names_from_sentence(sentence):
      """Extracts the names from a single sentence and returns them in a
      list.
  
      """
  
      names = list()
  
      production_names = sentence.productions()[1:]
  
      names_tagged = [tag.rhs() for tag in production_names]
      
      for name in names_tagged:
          this_name = [tag[0] for tag in name]
          names.append(' '.join(this_name))
  
      return names
#+END_SRC

We will then use this function and map it across the entire text,
accumulating the list of names.
#+BEGIN_SRC python :tangle "./src/snael.py"
  def get_names_from_text(text):
      """Extracts all names from a text.
      """
  
      names = set()
  
      for sentence in text:
          names = names.union(get_names_from_sentence(sentence))
  
      return list(names)
#+END_SRC

And viola, we have a list of names from the text.
#+BEGIN_SRC python :tangle "./src/snael.py"
  names = get_names_from_text(tagged_sentences)
#+END_SRC

*** TODO Resolve Anaphora
We now have =tagged_sentences= in memory; we have a /complete/ tagged
list of all words in the text, and have (hopefully) recognized all
explicit names.

But what about /implicit/ names?  In English, it is common to have
/anaphora/, the 'fancy term' for these implicit names.

Nota Bene: there are two differing definitions of /anaphora/:

1. the rhetorical device of repeating a sentence structure for
   emphasis
2. an expression who reference depends upon another referential
   expression

For example, the following phrase exhibits two cases of anaphora:

#+BEGIN_EXAMPLE
The fat cat tripped on itself.  The mouse then laughed at it.
#+END_EXAMPLE

**** The Problem
It is important to note that anaphora can manifest itself in reflexive
pronouns (/itself/) and in nominal pronouns (/it/), and neither need
be in the same sentence.  Furthermore, in objective pronouns, the
antecedant is often found further back in the text:

#+BEGIN_EXAMPLE
And he said, 'Then why do you worship Him?'
#+END_EXAMPLE
(cite)

In this example, =he= is referring to =Mr Bloom= (the protagonist) and
=Him= is referring to God, an entity named in dialogue.  Moreover,
consider the (contrived) example,

#+BEGIN_EXAMPLE
Pleased with himself, Matthew showed her the painting he drew.
#+END_EXAMPLE

And, for goodness' sake,

#+BEGIN_EXAMPLE
It is raining outside.
#+END_EXAMPLE

So we know a couple of things:

1. The pronoun can come before the noun.
2. The pronoun is almost /always/ gender-sensitive.
3. Due to the above, the pronoun can 'skip' other nouns and pronouns
   in order to reach its intended reference.
4. Sometimes, there simply /is no antecedant/.

Thus we are presented with many problems:

1. Resolving a pronoun isn't as easy as scanning the text and
   replacing each with the noun that precedes it.  (Even =it= skips
   =noun= and =text= to reach =pronoun=.)
2. The gender of pronouns raise worse issues still; it is almost
   impossible to determine the gender of a name without a dictionary
   and, if a pseudonym is gender-agnostic, it is simply impossible to
   resolve without multiple passes of a more advanced algorithm that
   can detect aliases.
3. Should such non-gendered actors exist, how can they be
   distinguished from non-actors?  (=The Spirit watched the city it
   guarded.=, where more complicated examples surely exist.)

The list goes on.  There is an existing portion of NLTK
(=nltk.sem.drt=) that 'deals with' anaphora, but its implementation is
needlessly cryptic for our purposes, difficult to work with, and
completely unreliable.  We will approach this with a basic, imperfect
algorithm that will resolve /some/ of the references, but will surely
not resolve /all/ of them.  It is better to miss a reference than to
create a wrong one, which NLTK's will often do.

**** The 'Solution'
Since we know this algorithm will be imperfect, we will encapsulate it
in its own method, =resolve_anaphora(text)=, which will simply return
a copy of =text= after replacing every positive instance of resolvable
anaphora with its antecedant.

Unfortunately, I'm not smart enough to do this.  Ho hum.

* TODO Resolve Aliases
Somehow resolve aliases and combine lists of occurances accordingly

Ideas
- Look for names that are part of other names; Mina \in Mina Murray;
  the Count \in Count Dracula

Define a function to see if two names are the same
#+BEGIN_SRC python :tangle "./src/snael.py"
  def same(name1, name2, treshold=.3):
      """Compares two names and determines if they refer to the same person.
      
      Arguments:
      - `name1`: A name
      - `name2`: A name
      """
      if name1 is name2:
          print 'Identical'
          return True
      if name1 in name2 or name2 in name1:
          print 'Contained'
          return True
  
      import ngram
   
      s = ngram.NGram.compare(name1, name2)
   
      if s > treshold:
          print '{} is {} (confidence {})'.format(name1, name2, s)
          return True
      return False
#+END_SRC

Look at names and combine those which are the same

Success is in sight!  We now have a 
#+BEGIN_SRC python :tangle "./src/snael.py"
  class Entity:
      def __init__(self, name):
          self.names = set([name])
          self.occurances = set()
  
      def find_occurances(self, text):
          for sentence in text:
              for name in self.names:
                  if name in sentence:
                      self.occurances.add(text.index(sentence))
  
      def same(self, entity, threshold=.6):
          """Absorbs `entity` into self if `entity` and self are sufficiently
   similar.
          
          Arguments:
          - `self`:
          - `entity`:
          """
          
          similarity = 0.0
  
          for my_name in self.names:
              for your_name in entity.names:
                  if same(my_name, your_name):
                      similarity += 1
  
          similarity_ratio = similarity / (len(self.names)*len(entity.names))
  
          return similarity_ratio >= treshold
  
      def absorb(self, entity):
          """Absorbs another entity
          
          Arguments:
          - `self`:
          - `entity`:
          """
          self.names |= entity.names
          self.occurances |= entity.occurances
#+END_SRC

Actually combine entities deemed to be the same
#+BEGIN_SRC python :tangle "./src/snael.py"
  people = [Entity(name) for name in names]
  
  # Self-stabalizing
  
  again = True
  while again:
      again = False
      for entity1 in people:
          for entity2 in people:
              if entity1.same(entity2):
                  again = True
                  entity1.absorb(entity2)
                  people.remove(entity2)
                  break
          if again:
              break
#+END_SRC

* DONE Find Occurances and Cooccurances
#+BEGIN_SRC python :tangle "./src/snael.py"
  for person in people:
      person.find_occurances(text)
  
  from itertools import combinations
  
  pairs = combinations(people, 2)
  
  network = Network()
  r = 5
  
  for A, B in pairs:
      for oA in A.occurances:
          for oB in B.occurances:
              if oB in range(oA-r, oA+r):
                  network.addConnection(A, B)
#+END_SRC


* TODO Output
** DONE Requirements
The output of this program is a list of name-name-weight tuples.
Since it is very possible that characters go by several names, the
very first name encountered will be used (if such aliases are
resolved at all).

The output is a plain text file that denotes detected aliases and
relationships.  All names are enclosed in a TeX-style group,
i.e. ={}=.  Aliases are a group of names set off by a bang (=!=).
Relationships are not set off so, and will always end in the strength
of the relationship.

Here is a contrived excerpt of ideal output obtained from a run on
Victor Hugo's Les Miserables: (note the actual values for weights in
the example are arbitrary)
#+BEGIN_EXAMPLE
  {!{Jean Valjean}
    {Monsieur Madeleine}
    {Ultime Fauchelevent}
    {Monsieur Leblanc}
    {Urbain Fabre}}
  {!{Javert}}
  {!{Cosette}
    {Euphrasie}
    {the Lark}
    {Medemoiselle Lanoire}
    {Ursula}}
  ...
  {{Jean Valjean}{Jondrette}{540}}
  {{Jean Valjean}{Javert}{550}}
  ...
#+END_EXAMPLE
** TODO Implementation
